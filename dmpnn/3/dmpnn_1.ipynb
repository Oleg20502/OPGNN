{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from lightning import pytorch as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "import chemprop\n",
    "from chemprop import data, featurizers, models, nn\n",
    "from chemprop.featurizers.molecule import RDKit2DFeaturizer\n",
    "from chemprop.utils import make_mol\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# logging.getLogger('lightning').setLevel(0)\n",
    "\n",
    "# configure logging at the root level of Lightning\n",
    "# logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
    "\n",
    "# configure logging on module level, redirect to file\n",
    "# logger = logging.getLogger(\"lightning.pytorch.core\")\n",
    "# logger.addHandler(logging.FileHandler(\"core.log\"))\n",
    "\n",
    "# logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.ERROR)\n",
    "# logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.ERROR)\n",
    "\n",
    "# logging.getLogger(\"lightning.fabric.plugins.environments.slurm\").setLevel(logging.ERROR)\n",
    "# logging.getLogger(\"lightning.pytorch.callbacks.model_checkpoint\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "# from skopt.plots import plot_objective\n",
    "# from skopt.plots import plot_convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "data_path = '../train_split_fluor.csv'\n",
    "\n",
    "smiles_columns = ['Chromophore', 'Solvent']\n",
    "target_columns = ['Absorption max (nm)', 'Emission max (nm)', 'log_q_yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0 # number of workers for dataloader. 0 means using main process for data loading\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_extra(df, columns):\n",
    "    return df[columns]\n",
    "\n",
    "def dropna(df):\n",
    "    return df.dropna(subset=['Absorption max (nm)', 'Emission max (nm)', 'Stokes shift', 'Quantum yield'], how='all')\n",
    "\n",
    "def replace_gas(df):\n",
    "    df.loc[df['Solvent'] == 'gas', 'Solvent'] = df['Chromophore']\n",
    "    return df\n",
    "\n",
    "def remove_neg_shift(df):\n",
    "    return df[(df['Stokes shift'] >= 0.0) | (df['Stokes shift'].isna())]\n",
    "\n",
    "def make_log_q_yield(df, eps=1e-5):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp.loc[df_tmp['Quantum yield'] == 0.0, 'Quantum yield'] = eps\n",
    "    df_tmp.loc[:, 'log_q_yield'] = np.log(df_tmp['Quantum yield'])\n",
    "    return df_tmp\n",
    "\n",
    "def delete_outliers(df, columns):\n",
    "    for column in columns:\n",
    "        print(column)\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        df = df[\n",
    "            ((df[column] > q1 - 1.5 * iqr) & (df[column] < q3 + 1.5 * iqr))\n",
    "            | (df[column].isna())\n",
    "        ]\n",
    "\n",
    "        print(\"left\", q1 - 1.5 * iqr)\n",
    "        print(\"right\", q3 + 1.5 * iqr)\n",
    "        print(\"=\" * 100)\n",
    "    return df\n",
    "\n",
    "def preprocess_train(df):\n",
    "    df = drop_extra(df, smiles_columns + ['Absorption max (nm)', 'Emission max (nm)', 'Stokes shift', 'Quantum yield'])\n",
    "    df = dropna(df)\n",
    "    df = replace_gas(df)\n",
    "    df = remove_neg_shift(df)\n",
    "    df = make_log_q_yield(df)\n",
    "    df = drop_extra(df, smiles_columns + target_columns)\n",
    "    return df\n",
    "\n",
    "def preprocess_test(df):\n",
    "    df = drop_extra(df, smiles_columns + ['Absorption max (nm)', 'Emission max (nm)', 'Stokes shift', 'Quantum yield'])\n",
    "    df = dropna(df)\n",
    "    df = replace_gas(df)\n",
    "    df = remove_neg_shift(df)\n",
    "    df = make_log_q_yield(df)\n",
    "    df = drop_extra(df, smiles_columns + target_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18110, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = preprocess_train(data_df)\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1850, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df = pd.read_csv('../test_split_fluor.csv')\n",
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_clean = preprocess_test(test_data_df)\n",
    "test_data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiss = data_clean.loc[:, smiles_columns].values\n",
    "ys = data_clean.loc[:, target_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_smiss = test_data_clean.loc[:, smiles_columns].values\n",
    "test_ys = test_data_clean.loc[:, target_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18110, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kashurin/soft/chemprop/chemprop/featurizers/molecule.py:52: UserWarning: The RDKit 2D features can deviate signifcantly from a normal distribution. Consider manually scaling them using an appropriate scaler before creating datapoints, rather than using the scikit-learn `StandardScaler` (the default in Chemprop).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "molecule_featurizer = RDKit2DFeaturizer()\n",
    "\n",
    "def generate_mol_features(smiss, save_file, molecule_featurizer=molecule_featurizer):\n",
    "    mols = [make_mol(smis, keep_h=False, add_h=False) for smis in smiss]\n",
    "    extra_datapoint_descriptors = [molecule_featurizer(mol) for mol in tqdm(mols)]\n",
    "    np.savez(save_file, extra_datapoint_descriptors)\n",
    "    return extra_datapoint_descriptors\n",
    "\n",
    "def load_mol_features(save_file):\n",
    "    extra_mol_features = np.load(save_file)\n",
    "    return [extra_mol_features[f\"arr_{i}\"] for i in range(len(extra_mol_features))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_file = 'rdkit_feats_1.npz'\n",
    "# extra_datapoint_descriptors_1 = generate_mol_features(smiss[:, 0], save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'rdkit_feats_1.npz'\n",
    "extra_datapoint_descriptors_1 = load_mol_features(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_file = 'rdkit_feats_2.npz'\n",
    "# extra_datapoint_descriptors_2 = generate_mol_features(smiss[:, 1], save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'rdkit_feats_2.npz'\n",
    "extra_datapoint_descriptors_2 = load_mol_features(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_file = 'rdkit_feats_1_test.npz'\n",
    "# extra_datapoint_descriptors_1_test = generate_mol_features(test_smiss[:, 0], save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'rdkit_feats_1_test.npz'\n",
    "extra_datapoint_descriptors_1_test = load_mol_features(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_file = 'rdkit_feats_2_test.npz'\n",
    "# extra_datapoint_descriptors_2_test = generate_mol_features(test_smiss[:, 1], save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'rdkit_feats_2_test.npz'\n",
    "extra_datapoint_descriptors_2_test = load_mol_features(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(extra_datapoint_descriptors_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18110, 420)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_datapoint_descriptors = np.concatenate((\n",
    "    extra_datapoint_descriptors_1,\n",
    "    extra_datapoint_descriptors_2),\n",
    "    axis=1\n",
    ")\n",
    "extra_datapoint_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, 420)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_datapoint_descriptors_test = np.concatenate((\n",
    "    extra_datapoint_descriptors_1_test,\n",
    "    extra_datapoint_descriptors_2_test),\n",
    "    axis=1\n",
    ")\n",
    "extra_datapoint_descriptors_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [[data.MoleculeDatapoint.from_smi(smis[0], y, x_d=X_d) \\\n",
    "             for smis, y, X_d in zip(smiss, ys, extra_datapoint_descriptors)]]\n",
    "all_data += [[data.MoleculeDatapoint.from_smi(smis[1]) \\\n",
    "              for smis in smiss]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [[data.MoleculeDatapoint.from_smi(smis[0], y, x_d=X_d) \\\n",
    "              for smis, y, X_d in zip(test_smiss, test_ys, extra_datapoint_descriptors_test)]]\n",
    "test_data += [[data.MoleculeDatapoint.from_smi(smis[1]) \\\n",
    "               for smis in test_smiss]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_to_split_by = 1\n",
    "mols = [d.mol for d in all_data[component_to_split_by]]\n",
    "train_indices, val_indices, test_indices = data.make_split_indices(mols, \"random\", (0.9, 0.05, 0.05))\n",
    "val_indices += test_indices\n",
    "train_data, val_data, _ = data.split_data_by_indices(\n",
    "    all_data, train_indices, val_indices, test_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18110"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]) + len(val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "train_datasets = [data.MoleculeDataset(train_data[i], featurizer) for i in range(len(smiles_columns))]\n",
    "val_datasets = [data.MoleculeDataset(val_data[i], featurizer) for i in range(len(smiles_columns))]\n",
    "test_datasets = [data.MoleculeDataset(test_data[i], featurizer) for i in range(len(smiles_columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mcdset = data.MulticomponentDataset(train_datasets)\n",
    "\n",
    "scaler = train_mcdset.normalize_targets()\n",
    "extra_datapoint_descriptors_scaler = train_mcdset.normalize_inputs(\"X_d\")\n",
    "\n",
    "val_mcdset = data.MulticomponentDataset(val_datasets)\n",
    "val_mcdset.normalize_targets(scaler)\n",
    "val_mcdset.normalize_inputs(\"X_d\", extra_datapoint_descriptors_scaler)\n",
    "\n",
    "test_mcdset = data.MulticomponentDataset(test_datasets)\n",
    "# tmp\n",
    "# test_mcdset.normalize_inputs(\"X_d\", extra_datapoint_descriptors_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_mcdset, batch_size=batch_size)\n",
    "val_loader = data.build_dataloader(val_mcdset, shuffle=False, batch_size=batch_size)\n",
    "test_loader = data.build_dataloader(test_mcdset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticomponentMPNN(\n",
       "  (message_passing): MulticomponentMessagePassing(\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x BondMessagePassing(\n",
       "        (W_i): Linear(in_features=86, out_features=512, bias=True)\n",
       "        (W_h): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=584, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (tau): ReLU()\n",
       "        (V_d_transform): Identity()\n",
       "        (graph_transform): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (agg): MeanAggregation()\n",
       "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=1444, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.5, inplace=False)\n",
       "        (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSELoss(task_weights=[[1.0, 1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (X_d_transform): ScaleTransform()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmp = nn.MulticomponentMessagePassing(\n",
    "    blocks=[\n",
    "        nn.BondMessagePassing(\n",
    "                d_h=512,\n",
    "                dropout=0.1,\n",
    "                depth=3,\n",
    "                bias=True\n",
    "            )\n",
    "        for _ in range(len(smiles_columns))],\n",
    "    n_components=len(smiles_columns),\n",
    ")\n",
    "\n",
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)\n",
    "\n",
    "ffn_input_dim = mcmp.output_dim + extra_datapoint_descriptors.shape[1]\n",
    "\n",
    "\n",
    "ffn = nn.RegressionFFN(\n",
    "    n_tasks=len(target_columns),\n",
    "    output_transform=output_transform,\n",
    "    input_dim=ffn_input_dim,\n",
    "    hidden_dim=512,\n",
    "    n_layers=4,\n",
    "    dropout=0.5,\n",
    "    activation=\"relu\"\n",
    ")\n",
    "\n",
    "X_d_transform = nn.ScaleTransform.from_standard_scaler(extra_datapoint_descriptors_scaler[0])\n",
    "\n",
    "mpnn = models.MulticomponentMPNN(\n",
    "    mcmp,\n",
    "    nn.MeanAggregation(),\n",
    "    ffn,\n",
    "    batch_norm=True,\n",
    "    warmup_epochs=5,\n",
    "    # init_lr=1e-5,\n",
    "    max_lr= 2 * 1e-4,\n",
    "    final_lr= 5 * 1e-5,\n",
    "    metrics=[nn.metrics.RMSEMetric()],\n",
    "    X_d_transform=X_d_transform\n",
    ")\n",
    "\n",
    "mpnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "model_dir = 'model_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kashurin/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kashurin/soft/miniconda3/envs/chemprop/lib/pyt ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/kashurin/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath=model_dir,\n",
    "    filename=\"{epoch:03d}-{val_loss:.3f}\"\n",
    ")\n",
    "\n",
    "earlystopping_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=15,\n",
    "    min_delta=0.0\n",
    ")\n",
    "\n",
    "# class MetricTracker(Callback):\n",
    "#     def __init__(self):\n",
    "#         self.collection = []\n",
    "    \n",
    "#     def on_validation_batch_end(trainer, module, outputs, ...):\n",
    "#         vacc = outputs['val_acc'] # you can access them here\n",
    "#         self.collection.append(vacc) # track them\n",
    "    \n",
    "#     def on_validation_epoch_end(trainer, module):\n",
    "#         elogs = trainer.logged_metrics # access it here\n",
    "#         self.collection.append(elogs)\n",
    "#         # do whatever is needed\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=True,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"cuda\",\n",
    "    devices=[device],\n",
    "    min_epochs=5,\n",
    "    max_epochs=200,\n",
    "    callbacks=[checkpoint_cb, earlystopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/kashurin/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n",
      "  | Name            | Type                         | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | message_passing | MulticomponentMessagePassing | 1.2 M  | train\n",
      "1 | agg             | MeanAggregation              | 0      | train\n",
      "2 | bn              | BatchNorm1d                  | 2.0 K  | train\n",
      "3 | predictor       | RegressionFFN                | 1.5 M  | train\n",
      "4 | X_d_transform   | ScaleTransform               | 0      | train\n",
      "-------------------------------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.979    Total estimated model params size (MB)\n",
      "37        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                           |…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc26cc14084046928e5ff791d557b228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                  |…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:212\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    211\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m batch, _, __ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/utilities/combined_loader.py:78\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators[i])\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/soft/chemprop/chemprop/data/datasets.py:401\u001b[0m, in \u001b[0;36mMulticomponentDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Datum]:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mdset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/soft/chemprop/chemprop/data/datasets.py:401\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Datum]:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets]\n",
      "File \u001b[0;32m~/soft/chemprop/chemprop/data/datasets.py:179\u001b[0m, in \u001b[0;36mMoleculeDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    178\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m--> 179\u001b[0m mg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmg_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Datum(mg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_ds[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_d[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY[idx], d\u001b[38;5;241m.\u001b[39mweight, d\u001b[38;5;241m.\u001b[39mlt_mask, d\u001b[38;5;241m.\u001b[39mgt_mask)\n",
      "File \u001b[0;32m~/soft/chemprop/chemprop/featurizers/molgraph/cache.py:89\u001b[0m, in \u001b[0;36mMolGraphCacheOnTheFly.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m MolGraph:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_featurizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_V_fs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_E_fs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/soft/chemprop/chemprop/featurizers/molgraph/molecule.py:76\u001b[0m, in \u001b[0;36mSimpleMoleculeMolGraphFeaturizer.__call__\u001b[0;34m(self, mol, atom_features_extra, bond_features_extra)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bond \u001b[38;5;129;01min\u001b[39;00m mol\u001b[38;5;241m.\u001b[39mGetBonds():\n\u001b[0;32m---> 76\u001b[0m     x_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbond_featurizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bond_features_extra \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/soft/chemprop/chemprop/featurizers/bond.py:63\u001b[0m, in \u001b[0;36mMultiHotBondFeaturizer.__call__\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbond_types) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstereo) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, b: Bond) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     64\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmpnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3706, device='cuda:1')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping_cb.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/kashurin/gnn_1/model_2/epoch=199-val_loss=0.342.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from the checkpoint at /home/kashurin/gnn_1/model_2/epoch=199-val_loss=0.342.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "batch_averaged_test/rmse    19.345558166503906\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = [None, 'model_'][0]\n",
    "if ckpt_path is None:\n",
    "    ckpt_path = 'best'\n",
    "results = trainer.test(mpnn, test_loader, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batch_averaged_test/rmse': 19.345558166503906}]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kashurin/gnn_3/model_1/epoch=112-val_loss=0.371.ckpt'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_cb.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kashurin/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kashurin/soft/miniconda3/envs/chemprop/lib/pyt ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/kashurin/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Restoring states from the checkpoint path at model_1/epoch=089-val_loss=0.387.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from the checkpoint at model_1/epoch=089-val_loss=0.387.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9f6bd726674a43b275056fb535bf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                |…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ckpt_path = checkpoint_cb.best_model_path\n",
    "ckpt_path = 'model_1/epoch=089-val_loss=0.387.ckpt'\n",
    "\n",
    "mpnn_predict = mpnn\n",
    "\n",
    "with torch.inference_mode():\n",
    "    trainer = pl.Trainer(\n",
    "        logger=None,\n",
    "        enable_progress_bar=True,\n",
    "        devices=[device]\n",
    "    )\n",
    "    testing_preds = trainer.predict(mpnn_predict, test_loader, ckpt_path=ckpt_path)\n",
    "\n",
    "testing_preds = np.concatenate(testing_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kashurin/soft/chemprop/chemprop/models/multi.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hparams = torch.load(checkpoint_path)[\"hyper_parameters\"]\n",
      "/home/kashurin/soft/miniconda3/envs/chemprop/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kashurin/soft/miniconda3/envs/chemprop/lib/pyt ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /home/kashurin/gnn_3/model_1/epoch=112-val_loss=0.371.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from the checkpoint at /home/kashurin/gnn_3/model_1/epoch=112-val_loss=0.371.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6bb62b020842e0a32bc9c7e790f2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                                |…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt_path = checkpoint_cb.best_model_path\n",
    "\n",
    "mpnn_predict = models.MulticomponentMPNN(\n",
    "    mcmp,\n",
    "    nn.MeanAggregation(),\n",
    "    ffn,\n",
    "    batch_norm=True,\n",
    "    warmup_epochs=5,\n",
    "    # init_lr=1e-5,\n",
    "    max_lr= 2 * 1e-4,\n",
    "    final_lr= 5 * 1e-5,\n",
    "    metrics=[nn.metrics.RMSEMetric()],\n",
    "    # X_d_transform=X_d_transform\n",
    ")\n",
    "\n",
    "mpnn_predict = mpnn_predict.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=None,\n",
    "    enable_progress_bar=True,\n",
    "    devices=[device]\n",
    ")\n",
    "testing_preds = trainer.predict(mpnn_predict, test_loader, ckpt_path=ckpt_path)\n",
    "\n",
    "testing_preds = np.concatenate(testing_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsd(pred, target):\n",
    "    mask = ~np.isnan(pred) & ~np.isnan(target)\n",
    "    return root_mean_squared_error(pred[mask], target[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSD Absorption max, nm: 1.1555909874362796e+33\n",
      "RMSD Emission max, nm: 2.5358526076256896e+33\n",
      "RMSD Log quantum yield, nm: 2.8968111544773912e+26\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSD Absorption max, nm: {rmsd(testing_preds[:, 0], test_ys[:, 0])}\")\n",
    "print(f\"RMSD Emission max, nm: {rmsd(testing_preds[:, 1], test_ys[:, 1])}\")\n",
    "print(f\"RMSD Log quantum yield, nm: {rmsd(testing_preds[:, 2], test_ys[:, 2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(testing_preds[:, 0], test_ys[:, 0])\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "def r2(pred, target):\n",
    "    mask = ~np.isnan(pred) & ~np.isnan(target)\n",
    "    return r2_score(pred[mask], target[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Absorption max: 0.9458543760636822\n",
      "R2 Emission max: 0.9031947139046643\n",
      "R2 Log quantum yield: 0.6496614997928065\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 Absorption max: {r2(testing_preds[:, 0], test_ys[:, 0])}\")\n",
    "print(f\"R2 Emission max: {r2(testing_preds[:, 1], test_ys[:, 1])}\")\n",
    "print(f\"R2 Log quantum yield: {r2(testing_preds[:, 2], test_ys[:, 2])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
